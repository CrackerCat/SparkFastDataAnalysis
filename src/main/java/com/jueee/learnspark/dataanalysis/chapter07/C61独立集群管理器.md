### 7.6.1　独立集群管理器 ###
这种集群管理器由一个主节点和几个工作节点组成，各自都分配有一定量的内存和 CPU 核心。  
当提交应用时，可以配置执行器进程使用的内存量，以及所有执行器进程使用的 CPU 核心总数。  

#### 启动独立集群管理器 ####
要使用集群启动脚本，请按如下步骤执行：
1.  将编译好的 Spark 复制到所有机器的一个相同的目录下，比如 /home/yourname/spark。
2.  设置好从主节点机器到其他机器的 SSH 无密码登陆。
3.  编辑主节点的 conf/slaves 文件并填上所有工作节点的主机名。
4.  在主节点上运行 sbin/start-all.sh （要在主节点上运行而不是在工作节点上）以启动集群。
5.  要停止集群，在主节点上运行 bin/stop-all.sh 。

#### 提交应用 ####
``` 
spark-submit --master spark://masternode:7077 yourapp
```

#### 配置资源用量 ####
-   执行器进程内存  
可以通过 spark-submit 的 --executor-memory 参数来配置此项。  
每个应用在每个工作节点上最多拥有一个执行器进程，因此这个设置项能够控制执行器节点占用工作节点的多少内存。

-   占用核心总数的最大值  
这是一个应用中所有执行器进程所占用的核心总数。此项的默认值是无限。  
可以通过 spark-submit 的 --total-executorcores 参数设置这个值，或者在你的 Spark 配置文件中设置 spark.cores.max 的值。  

#### 高度可用性 ####
独立模式能够很好地支持工作节点的故障。  

如果你想让集群的主节点也拥有高度可用性，Spark 还支持使用 Apache ZooKeeper（一个分布式协调系统）来维护多个备用的主节点，并在一个主节点失败时切换到新的主节点上。