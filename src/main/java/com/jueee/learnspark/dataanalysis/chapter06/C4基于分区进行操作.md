### 6.4　基于分区进行操作 ###
基于分区对数据进行操作可以让我们避免为每个数据元素进行重复的配置工作。  
诸如打开数据库连接或创建随机数生成器等操作，都是我们应当尽量避免为每个元素都配置一次的工作。  

Spark 提供基于分区的 map 和 foreach ，让部分代码只对 RDD 的每个分区运行一次，这样可以帮助降低这些操作的代价。

使用 mapPartitions 函数获得输入 RDD 的每个分区中的元素迭代器，而需要返回的是执行结果的序列的迭代器。
当基于分区操作 RDD 时，Spark 会为函数提供该分区中的元素的迭代器。返回值方面，也返回一个迭代器。  

除了避免重复的配置工作，也可以使用 mapPartitions() 避免创建对象的开销。  

#### 代码 ####
-   [Python](P4PerPartition.py)
-   [Scala](S4PerPartition.scala)
-   [Java](J4PerPartition.java)