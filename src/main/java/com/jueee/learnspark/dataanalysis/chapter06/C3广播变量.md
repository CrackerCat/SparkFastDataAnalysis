### 6.3　广播变量 ###
广播变量可以让程序高效地向所有工作节点发送一个较大的只读值，以供一个或多个 Spark 操作使用。  
比如，如果你的应用需要向所有节点发送一个较大的只读查询表，甚至是机器学习算法中的一个很大的特征向量，广播变量用起来都很顺手。  

Spark 会自动把闭包中所有引用到的变量发送到工作节点上。虽然这很方便，但也很低效。
1.  默认的任务发射机制是专门为小任务进行优化的。
2.  事实上你可能会在多个并行操作中使用同一个变量，但是 Spark 会为每个操作分别发送。

广播变量其实就是类型为 spark.broadcast.Broadcast[T] 的一个对象，其中存放着类型为 T 的值。  
可以在任务中通过对 Broadcast 对象调用 value 来获取该对象的值。  
这个值只会被发送到各节点一次，使用的是一种高效的类似 BitTorrent 的通信机制。
  
#### 使用过程 ####
使用广播变量的过程很简单：
1.  通过对一个类型 T 的对象调用 SparkContext.broadcast 创建出一个 Broadcast[T] 对象。  
任何可序列化的类型都可以这么实现。
2.  通过 value 属性访问该对象的值（在 Java 中为 value() 方法）。
3.  变量只会被发到各个节点一次，应作为只读值处理（修改这个值不会影响到别的节点）。

满足只读要求的最容易的使用方式是广播基本类型的值或者引用不可变对象。  
在这样的情况下，你没有办法修改广播变量的值，除了在驱动器程序的代码中可以修改。
  
#### 广播的优化 ####
Spark 的 Scala 和 Java API 中默认使用的序列化库为 Java 序列化库，因此它对于除基本类型的数组以外的任何对象都比较低效。  
可以使用 spark.serializer 属性选择另一个序列化库来优化序列化过程。
也可以为你的数据类型实现自己的序列化方式。
-   对 Java 对象使用 java.io.Externalizable 接口实现序列化
-   使用 reduce() 方法为 Python 的 pickle 库定义自定义的序列化

#### 代码 ####
-   [Python](P3BroadcastVariables.py)
-   [Scala](S3BroadcastVariables.scala)
-   [Java](J3BroadcastVariables.java)