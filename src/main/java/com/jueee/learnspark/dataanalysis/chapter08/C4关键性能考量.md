### 8.4　关键性能考量 ###

#### 8.4.1　并行度 ####
并行度会从两方面影响程序的性能：
1.  当并行度过低时，Spark 集群会出现资源闲置的情况。
2.  当并行度过高时，每个分区产生的间接开销累计起来就会更大。

评判并行度是否过高的标准包括任务是否是几乎在瞬间（毫秒级）完成的，或者是否观察到任务没有读写任何数据。  

Spark 提供了两种方法来对操作的并行度进行调优：
1.  第一种方法是在数据混洗操作时，使用参数的方式为混洗后的 RDD 指定并行度。  
2.  第二种方法是对于任何已有的 RDD，可以进行重新分区来获取更多或者更少的分区数。  
重新分区操作通过 repartition() 实现，该操作会把 RDD 随机打乱并分成设定的分区数目。  
如果你确定要减少 RDD 分区，可以使用coalesce() 操作。由于没有打乱数据，该操作比 repartition() 更为高效。  

#### 8.4.2　序列化格式 ####
当 Spark 需要通过网络传输数据，或是将数据溢写到磁盘上时，Spark 需要把数据序列化为二进制格式。  
序列化会在数据进行混洗操作时发生，此时有可能需要通过网络传输大量数据。  

默认情况下，Spark 会使用 Java 内建的序列化库。  
Spark 也支持使用第三方序列化库 [Kryo](https://github.com/EsotericSoftware/kryo)，可以提供比 Java 的序列化工具更短的序列化时间和更高压缩比的二进制表示，但不能直接序列化全部类型的对象。

##### 使用 Kryo 序列化 #####
要使用 Kryo 序列化工具，你需要设置 spark.serializer 为 org.apache.spark.serializer.KryoSerializer 。  
为了获得最佳性能，你还应该向 Kryo 注册你想要序列化的类。  

注册类可以让 Kryo 避免把每个对象的完整的类名写下来，成千上万条记录累计节省的空间相当可观。  
如果你想强制要求这种注册，可以把 spark.kryo.registrationRequired 设置为 true ，这样 Kryo 会在遇到未注册的类时抛出错误。
``` 
val conf = new SparkConf()
conf.set("spark.serializer", "org.apache.spark.serializer.KryoSerializer")
// 严格要求注册类
conf.set("spark.kryo.registrationRequired", "true")
conf.registerKryoClasses(Array(classOf[MyClass], classOf[MyOtherClass]))
```

#### 8.4.3　内存管理 ####
在各个执行器进程中，内存有以下所列几种用途：
-   **RDD存储**   
当调用 RDD 的 persist() 或 cache() 方法时，这个 RDD 的分区会被存储到缓存区中。  
Spark 会根据 spark.storage.memoryFraction 限制用来缓存的内存占整个 JVM 堆空间的比例大小。  
如果超出限制，旧的分区数据会被移出内存。

-   **数据混洗与聚合的缓存区**  
当进行数据混洗操作时，Spark 会创建出一些中间缓存区来存储数据混洗的输出数据。  
这些缓存区用来存储聚合操作的中间结果，以及数据混洗操作中直接输出的部分缓存数据。  
Spark 会尝试根据 spark.shuffle.memoryFraction 限定这种缓存区内存占总内存的比例。

-   **用户代码**  
Spark 可以执行任意的用户代码，所以用户的函数可以自行申请大量内存。  
例如，如果一个用户应用分配了巨大的数组或者其他对象，那这些都会占用总的内存。  
用户代码可以访问 JVM 堆空间中除分配给 RDD 存储和数据混洗存储以外的全部剩余空间。  

在默认情况下，Spark 会使用 60％的空间来存储 RDD，20% 存储数据混洗操作产生的数据，剩下的 20% 留给用户程序。  
用户可以自行调节这些选项来追求更好的性能表现。

#### 8.4.4　硬件供给 ####
影响集群规模的主要参数包括分配：
-   给每个执行器节点的内存大小  
可以通过 spark.executor.memory 配置项或者 spark-submit 的 --executor-memory 标记来设置。
-   每个执行器节点占用的核心数，取决于各种部署模式。  
在 YARN 模式下，你可以通过 spark.executor.cores 或 --executor-cores 标 记 来 设 置 执 行 器 节 点 的 核 心 数， 通 过 --num-executors 设置执行器节点的总数。  
在 Mesos 和独立模式中，Spark 则会从调度器提供的资源中获取尽可能多的核心以用于执行器节点。  
-   执行器节点总数
-   用来存储临时数据的本地磁盘数量

“越多越好”的原则在设置执行器节点内存时并不一定适用。  
使用巨大的堆空间可能会导致垃圾回收的长时间暂停，从而严重影响 Spark 作业的吞吐量。



