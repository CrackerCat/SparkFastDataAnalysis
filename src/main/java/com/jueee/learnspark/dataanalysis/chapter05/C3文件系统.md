### 5.3　文件系统 ###
Spark 支持读写很多种文件系统，可以使用任何我们想要的文件格式。
#### 本地/“常规”文件系统 ####
Spark 支持从本地文件系统中读取文件，不过它要求文件在集群中所有节点的相同路径下都可以找到。  

在 Scala 中从本地文件系统读取一个压缩的文本文件：
```
val rdd = sc.textFile("file:///home/holden/happypandas.gz")
```
如果文件还没有放在集群中的所有节点上，你可以在驱动器程序中从本地读取该文件而无需使用整个集群，然后再调用 parallelize 将内容分发给工作节点。  
不过这种方式可能会比较慢，所以推荐的方法是将文件先放到像 HDFS、NFS、S3 等共享文件系统上。
#### Amazon S3 ####
用 Amazon S3 来存储大量数据正日益流行。  
当计算节点部署在 Amazon EC2 上的时候，使用 S3 作为存储尤其快，但是在需要通过公网访问数据时性能会差很多。

要在 Spark 中访问 S3 数据，你应该首先把你的 S3 访问凭据设置为 AWS_ACCESS_KEY_ID 和 AWS_SECRET_ACCESS_KEY 环境变量。  
将一个以 s3n:// 开头的路径以 s3n://bucket/path-within-bucket 的形式传给Spark 的输入方法。
#### HDFS ####
Hadoop 分布式文件系统（HDFS）是一种广泛使用的文件系统，Spark 能够很好地使用它。  
HDFS 被设计为可以在廉价的硬件上工作，有弹性地应对节点失败，同时提供高吞吐量。  
Spark 和 HDFS 可以部署在同一批机器上，这样 Spark 可以利用数据分布来尽量避免一些网络开销。

在 Spark 中使用 HDFS 只需要将输入输出路径指定为 hdfs://master:port/path 就够了。