### 5.2　文件格式 ###
Spark支持的一些常见格式  
<table>
<tr><th>格式名称</th><th>结构化</th><th>备注</th></tr>  
<tr><td>文本文件</td><td>否</td><td>普通的文本文件，每行一条记录</td></tr>
<tr><td>JSON</td><td>半结构化</td><td>常见的基于文本的格式，半结构化；大多数库都要求每行一条记录</td></tr>
<tr><td>CSV</td><td>是</td><td>非常常见的基于文本的格式，通常在电子表格应用中使用</td></tr>
<tr><td>SequenceFiles</td><td>是</td><td>一种用于键值对数据的常见 Hadoop 文件格式</td></tr>
<tr><td>Protocol buffers</td><td>是</td><td>一种快速、节约空间的跨语言格式</td></tr>
<tr><td>对象文件</td><td>是</td><td>用来将Spark作业中的数据存储下来以让共享的代码读取。改变类的时候它会失效，因为它依赖于Java序列化</td></tr>
</table>
除了 Spark 中直接支持的输出机制，还可以对键数据（或成对数据）使用 Hadoop 的新旧文件 API。  
由于 Hadoop 接口要求使用键值对数据，所以也只能这样用，即使有些格式事实上忽略了键。  
对于那些会忽视键的格式，通常使用假的键（比如 null ）。