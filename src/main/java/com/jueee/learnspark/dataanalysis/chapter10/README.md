### 第 10 章	Spark Streaming ###
Spark Streaming 允许用户使用一套和批处理非常接近的 API 来编写流式计算应用，这样就可以大量重用批处理应用的技术甚至代码。  

和 Spark 基于 RDD 的概念很相似，Spark Streaming 使用离散化流（discretized stream）作为抽象表示，叫作 DStream。  
DStream 是随时间推移而收到的数据的序列。  

在内部，每个时间区间收到的数据都作为 RDD 存在，而 DStream 是由这些 RDD 所组成的序列（因此得名“离散化”）。  
DStream 可以从各种输入源创建，比如 Flume、Kafka 或者 HDFS。  

创建出来的 DStream 支持两种操作：
-   转化操作（transformation），会生成一个新的 DStream
-   输出操作（output operation），可以把数据写入外部系统中。  

DStream 提供了许多与 RDD 所支持的操作相类似的操作支持，还增加了与时间相关的新操作，比如滑动窗口。

#### 本章目录 ####
1.	[一个简单的例子](C1一个简单的例子.md)    
2.	[架构与抽象](C2架构与抽象.md)    
3.	[转化操作](C3转化操作.md)    
3.1	无状态转化操作    
3.2	有状态转化操作    
4.	[输出操作](C4输出操作.md)    
5.	[输入源](C5输入源.md)    
5.1	核心数据源   
5.2	附加数据源    
5.3	多数据源与集群规模    
6.	[24/7 不间断运行](C6不间断运行.md)    
6.1	检查点机制    
6.2	驱动器程序容错    
6.3	工作节点容错    
6.4	接收器容错    
6.5	处理保证    
7.	[Streaming 用户界面](C7Streaming用户界面.md)    
8.	[性能考量](C8性能考量.md)    
8.1	批次和窗口大小    
8.2	并行度    
8.3	垃圾回收和内存使用   
#### 本章总结 ####    
-   如何使用 DStream 操作流数据。