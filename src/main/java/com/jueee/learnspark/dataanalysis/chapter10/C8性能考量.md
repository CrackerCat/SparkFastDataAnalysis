### 10.8　性能考量 ###
#### 批次和窗口大小 ####
总的来说，500 毫秒已经被证实为对许多应用而言是比较好的最小批次大小。  

寻找最小批次大小的最佳实践是从一个比较大的批次大小（10 秒左右）开始，不断使用更小的批次大小。  

如果 Streaming 用户界面中显示的处理时间保持不变，你就可以进一步减小批次大小。如果处理时间开始增加，你可能已经达到了应用的极限。

#### 并行度 ####
有以下三种方式可以提高并行度：
-   **增加接收器数目**  
有时如果记录太多导致单台机器来不及读入并分发的话，接收器会成为系统瓶颈。这时
你就需要通过创建多个输入 DStream（这样会创建多个接收器）来增加接收器数目，然
后使用 union 来把数据合并为一个数据源。

-   **将收到的数据显式地重新分区**  
如果接收器数目无法再增加，你可以通过使用 DStream.repartition 来显式重新分区输
入流（或者合并多个流得到的数据流）来重新分配收到的数据。

-   **提高聚合计算的并行度**  
对于像 reduceByKey() 这样的操作，你可以在第二个参数中指定并行度，我们在介绍
RDD 时提到过类似的手段。

#### 垃圾回收和内存使用 ####
Java 的垃圾回收机制（简称 GC）也可能会引起问题。  

可以通过打开 Java 的并发标志清除收集器（Concurrent Mark-Sweep garbage collector）来减少 GC 引起的不可预测的长暂停。  

并发标志—清除收集器总体上会消耗更多的资源，但是会减少暂停的发生。
可以通过在配置参数 spark.executor.extraJavaOptions 中添加 -XX:+UseConcMarkSweepGC来控制选择并发标志—清除收集器。

```
打开并发标志—清除收集器：
spark-submit --conf spark.executor.extraJavaOptions=-XX:+UseConcMarkSweepGC App.jar
```

还可以通过减轻 GC 的压力来大幅度改善性能。  






