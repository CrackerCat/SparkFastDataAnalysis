### 10.6　24/7不间断运行 ###
Spark Streaming 的一大优势在于它提供了强大的容错性保障。  

要不间断运行 Spark Streaming 应用，需要一些特别的配置。
1.  设置好诸如 HDFS 或 Amazon S3 等可靠存储系统中的检查点机制。 
2.  考虑驱动器程序的容错性（需要特别的配置代码）以及对不可靠输入源的处理。

### 检查点机制 ###
检查点机制是我们在 Spark Streaming 中用来保障容错性的主要机制。  
它可以使 Spark Streaming 阶段性地把应用数据存储到诸如 HDFS 或 Amazon S3 这样的可靠存储系统中，以供恢复时使用。  

具体来说，检查点机制主要为以下两个目的服务。
-   控制发生失败时需要重算的状态数。  

-   提供驱动器程序容错。  
如果流计算应用中的驱动器程序崩溃了，你可以重启驱动器程序并让驱动器程序从检查点恢复，这样 Spark Streaming 就可以读取之前运行的程序处理数据的进度，并从那里继续。

可以通过向 ssc.checkpoint() 方法传递一个路径参数（HDFS、S3 或者本地路径均可）来配置检查点机制。

### 驱动器程序容错 ###
驱动器程序的容错要求我们以特殊的方式创建 StreamingContext。  
需要把检查点目录提供给 StreamingContext。  
与直接调用 new StreamingContext 不同，应该使用StreamingContext.getOrCreate() 函数。
-   [Java](J6DriverFaultTolerance.java)
-   [Scala](S6DriverFaultTolerance.scala)

### 工作节点容错 ###
为了应对工作节点失败的问题，Spark Streaming 使用与 Spark 的容错机制相同的方法。  
所有从外部数据源中收到的数据都在多个工作节点上备份。  
所有从备份数据转化操作的过程中创建出来的 RDD 都能容忍一个工作节点的失败，因为根据 RDD 谱系图，系统可以把丢失的数据从幸存的输入数据备份中重算出来。

### 接收器容错 ###
接收器提供以下保证。
-   所有从可靠文件系统中读取的数据（比如通过 StreamingContext.hadoopFiles 读取的）都是可靠的，因为底层的文件系统是有备份的。  
Spark Streaming 会记住哪些数据存放到了检查点中，并在应用崩溃后从检查点处继续执行。

-   对于像 Kafka、推式 Flume、Twitter 这样的不可靠数据源，Spark 会把输入数据复制到其他节点上，但是如果接收器任务崩溃，Spark 还是会丢失数据。

### 处理保证 ###
当把转化操作得到的结果使用输出操作推入外部系统中时，写结果的任务可能因故障而执行多次，一些数据可能也就被写了多次。  

由于这引入了外部系统，因此我们需要专门针对各系统的代码来处理这样的情况。  

我们可以使用事务操作来写入外部系统（即原子化地将一个 RDD 分区一次写入），或者设计幂等的更新操作（即多次运行同一个更新操作仍生成相同的结果）。比如 Spark Streaming 的 saveAs...File 操作会在一个文件写完时自动
将其原子化地移动到最终位置上，以此确保每个输出文件只存在一份。

